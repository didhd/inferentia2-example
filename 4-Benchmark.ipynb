{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ef5644c-2f34-4cca-861a-f11548a67caa",
   "metadata": {},
   "source": [
    "## 성능 측정\n",
    "TinyLLama 모델을 Inferentia2에 성공적으로 배포하였으니, 이제 이 모델의 성능을 벤치마킹하기 위해 코드를 다운로드하고 모델의 성능을 측정할 준비를 합니다. 다음 명령어를 통해 벤치마크를 실행할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92b1c960-a40c-4548-9aa0-0c9474fd5c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [00:33<00:00,  2.98it/s]\n"
     ]
    }
   ],
   "source": [
    "!python benchmark.py --endpoint http://127.0.0.1:8080/predictions/tinyllama --num-concurrent-requests 25 --max-num-completed-requests 100 --seq-length 512 --timeout 600 --results-dir results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62efe7df-79aa-400a-82fa-e7feea7e3e4e",
   "metadata": {},
   "source": [
    "이 명령은 동시에 25명의 사용자가 최대 100개의 요청을 처리하면서, 모델의 첫 토큰까지의 시간, 토큰당 지연 시간(ms/token) 및 처리량(tokens/s)을 측정합니다. 이 모든 상세 결과는 결과 폴더에서 확인할 수 있습니다.\n",
    "\n",
    "이제 결과를 파싱하고 표시해 보겠습니다. 다음은 Python 코드와 그 출력 결과입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "845c3cc1-a176-41d5-bfce-b86f1009e79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concurrent requests: 25\n",
      "Avg. Input token length: 512.0\n",
      "Avg. Output token length: 28.0\n",
      "Avg. First-Time-To-Token: 335.07ms\n",
      "Avg. Throughput: 83.54 tokens/sec\n",
      "Avg. Latency: 17.07ms/token\n"
     ]
    }
   ],
   "source": [
    "# 결과 폴더에서 summary.json 파일을 읽고 결과를 출력\n",
    "import glob\n",
    "import json\n",
    "\n",
    "with open(glob.glob('results/*summary.json')[0], 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "print(\"Concurrent requests: 25\")\n",
    "print(f\"Avg. Input token length: {data['results']['avg_input_tokens']}\")\n",
    "print(f\"Avg. Output token length: {data['results']['avg_output_tokens']}\")\n",
    "print(f\"Avg. First-Time-To-Token: {data['results']['avg_first_token_time']:.2f}ms\")\n",
    "print(f\"Avg. Throughput: {data['results']['avg_throughput']:.2f} tokens/sec\")\n",
    "print(f\"Avg. Latency: {data['results']['avg_latency']:.2f}ms/token\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
